{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83c\udf93 Student Performance Analysis and Prediction (Theory & Practical)\n", "### Exploratory Data Analysis and Visualization (U21ADP05)\n", "**Student:** Surya J  |  **Roll No:** 23AD059  |  **Department:** AI & DS\n", "\n", "This notebook explores a student performance dataset through EDA, visualization, and modeling using a Multilayer Perceptron (MLP) neural network."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# ==============================================================\n", "# STUDENT PERFORMANCE ANALYSIS AND PREDICTION PROJECT\n", "# Exploratory Data Analysis and Visualization (U21ADP05)\n", "# Author: Surya J | Roll No: 23AD059 | Dept: AI & DS | Year/Sem: V / Odd Sem\n", "# ==============================================================\n", "\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n", "from sklearn.compose import ColumnTransformer\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n", "import tensorflow as tf\n", "from tensorflow import keras\n", "from tensorflow.keras import layers\n", "import warnings\n", "warnings.filterwarnings('ignore')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load dataset\n", "df = pd.read_csv('student_performance.csv')\n", "print('\u2705 Dataset Loaded! Shape:', df.shape)\n", "df.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Basic info and summary\n", "df.info()\n", "df.describe(include='all').T"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Check missing values and duplicates\n", "print('Missing Values:\\n', df.isna().sum())\n", "print('\\nDuplicate Rows:', df.duplicated().sum())\n", "df = df.fillna(df.median(numeric_only=True))\n", "df = df.drop_duplicates().reset_index(drop=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Select target column\n", "target_col = 'theory_score'\n", "if target_col not in df.columns:\n", "    target_col = df.select_dtypes(include=[np.number]).columns[-1]\n", "y = df[target_col]\n", "X = df.drop(columns=[target_col])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Visualizations\n", "sns.set(style='whitegrid', palette='muted')\n", "\n", "# 1. Histogram\n", "sns.histplot(df[target_col], kde=True)\n", "plt.title('Distribution of Theory Scores')\n", "plt.show()\n", "\n", "# 2. Boxplot by gender\n", "if 'gender' in df.columns:\n", "    sns.boxplot(x='gender', y=target_col, data=df)\n", "    plt.title('Theory Score by Gender')\n", "    plt.show()\n", "\n", "# 3. Correlation heatmap\n", "sns.heatmap(df.select_dtypes(include=[np.number]).corr(), annot=True, cmap='coolwarm')\n", "plt.title('Correlation Heatmap')\n", "plt.show()\n", "\n", "# 4. Pairplot\n", "num_cols = df.select_dtypes(include=[np.number]).columns[:5]\n", "sns.pairplot(df[num_cols])\n", "plt.suptitle('Pairwise Relationships', y=1.02)\n", "plt.show()\n", "\n", "# 5. Scatter Plot\n", "if 'practical_score' in df.columns:\n", "    sns.scatterplot(x='practical_score', y='theory_score', data=df)\n", "    plt.title('Theory vs Practical Scores')\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Preprocessing\n", "cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n", "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n", "if target_col in num_cols:\n", "    num_cols.remove(target_col)\n", "\n", "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n", "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n", "\n", "preprocessor = ColumnTransformer(transformers=[\n", "    ('num', numeric_transformer, num_cols),\n", "    ('cat', categorical_transformer, cat_cols)\n", "])\n", "\n", "X_prepared = preprocessor.fit_transform(X)\n", "print('\u2705 Preprocessing Complete! Shape:', X_prepared.shape)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Split data\n", "X_train_val, X_test, y_train_val, y_test = train_test_split(X_prepared, y, test_size=0.15, random_state=42)\n", "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1765, random_state=42)\n", "print('Train:', X_train.shape, 'Val:', X_val.shape, 'Test:', X_test.shape)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Build MLP Model\n", "def build_mlp(input_dim, lr=0.001, hidden=[128,64], dropout=0.2):\n", "    model = keras.Sequential()\n", "    model.add(layers.InputLayer(input_shape=(input_dim,)))\n", "    for h in hidden:\n", "        model.add(layers.Dense(h, activation='relu'))\n", "        model.add(layers.Dropout(dropout))\n", "    model.add(layers.Dense(1))\n", "    model.compile(optimizer=keras.optimizers.Adam(lr), loss='mse',\n", "                  metrics=[keras.metrics.RootMeanSquaredError(name='rmse'), keras.metrics.MeanAbsoluteError(name='mae')])\n", "    return model\n", "\n", "model = build_mlp(X_train.shape[1])\n", "model.summary()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train model\n", "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n", "history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n", "                    epochs=100, batch_size=32, callbacks=[early_stop], verbose=2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Evaluation plots\n", "plt.plot(history.history['loss'], label='Train Loss')\n", "plt.plot(history.history['val_loss'], label='Val Loss')\n", "plt.title('Loss vs Epoch')\n", "plt.legend()\n", "plt.show()\n", "\n", "plt.plot(history.history['mae'], label='Train MAE')\n", "plt.plot(history.history['val_mae'], label='Val MAE')\n", "plt.title('MAE vs Epoch')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Test evaluation\n", "y_pred = model.predict(X_test).flatten()\n", "mse = mean_squared_error(y_test, y_pred)\n", "rmse = np.sqrt(mse)\n", "mae = mean_absolute_error(y_test, y_pred)\n", "r2 = r2_score(y_test, y_pred)\n", "\n", "print(f'\ud83d\udcca MSE: {mse:.3f} | RMSE: {rmse:.3f} | MAE: {mae:.3f} | R2: {r2:.3f}')\n", "\n", "sns.scatterplot(x=y_test, y=y_pred)\n", "plt.xlabel('Actual'); plt.ylabel('Predicted')\n", "plt.title('Actual vs Predicted')\n", "plt.show()\n", "\n", "sns.histplot(y_test - y_pred, kde=True)\n", "plt.title('Error Distribution')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Save model\n", "model.save('mlp_student_performance_model.h5')\n", "print('\u2705 Model Saved Successfully!')"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}